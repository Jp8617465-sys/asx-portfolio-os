{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model D Validation Notebook\n",
        "\n",
        "This notebook validates the Model D pipeline end-to-end:\n",
        "- Trend stability from `fundamentals_history` or `features_fundamental_trends`.\n",
        "- Beta distribution from price returns.\n",
        "- Factor correlation heatmap for derived trend features.\n",
        "\n",
        "It is safe to run even if tables are missing; the notebook will print guidance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import warnings\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sqlalchemy import create_engine, text\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "DATABASE_URL = os.getenv(\"DATABASE_URL\")\n",
        "if not DATABASE_URL:\n",
        "    raise SystemExit(\"DATABASE_URL not set\")\n",
        "\n",
        "engine = create_engine(DATABASE_URL)\n",
        "\n",
        "def table_exists(table_name: str) -> bool:\n",
        "    with engine.connect() as conn:\n",
        "        result = conn.execute(text(\"select to_regclass(:t)\"), {\"t\": table_name})\n",
        "        return result.scalar() is not None\n",
        "\n",
        "print(\"Connected to database.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load tables if available\n",
        "fundamentals_history = None\n",
        "features_trends = None\n",
        "prices = None\n",
        "\n",
        "if table_exists(\"fundamentals_history\"):\n",
        "    fundamentals_history = pd.read_sql(\"select ticker, as_of, metric, value from fundamentals_history\", engine)\n",
        "    print(f\"fundamentals_history rows: {len(fundamentals_history):,}\")\n",
        "else:\n",
        "    print(\"fundamentals_history not found.\")\n",
        "\n",
        "if table_exists(\"features_fundamental_trends\"):\n",
        "    features_trends = pd.read_sql(\n",
        "        \"select ticker, metric, window, mean_value, pct_change, slope, volatility, as_of \"\n",
        "        \"from features_fundamental_trends\",\n",
        "        engine,\n",
        "    )\n",
        "    print(f\"features_fundamental_trends rows: {len(features_trends):,}\")\n",
        "else:\n",
        "    print(\"features_fundamental_trends not found.\")\n",
        "\n",
        "if table_exists(\"prices\"):\n",
        "    prices = pd.read_sql(\n",
        "        \"select dt, symbol, close from prices order by symbol, dt\",\n",
        "        engine,\n",
        "    )\n",
        "    print(f\"prices rows: {len(prices):,}\")\n",
        "else:\n",
        "    print(\"prices not found.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Trend stability (slope and percent change)\n",
        "\n",
        "If `features_fundamental_trends` exists, use it directly. Otherwise, derive simple slopes from\n",
        "`fundamentals_history` by ticker/metric. This validates whether factor trends are stable and\n",
        "directional across the universe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trend_df = None\n",
        "if features_trends is not None and not features_trends.empty:\n",
        "    trend_df = features_trends.copy()\n",
        "elif fundamentals_history is not None and not fundamentals_history.empty:\n",
        "    # Simple derivation for validation only\n",
        "    trend_rows = []\n",
        "    for (ticker, metric), grp in fundamentals_history.groupby([\"ticker\", \"metric\"]):\n",
        "        grp = grp.sort_values(\"as_of\").tail(8)\n",
        "        if len(grp) < 3:\n",
        "            continue\n",
        "        x = np.arange(len(grp))\n",
        "        y = grp[\"value\"].astype(float).values\n",
        "        slope = np.polyfit(x, y, 1)[0]\n",
        "        pct_change = (y[-1] / y[0]) - 1 if y[0] not in (0, None) else np.nan\n",
        "        trend_rows.append({\n",
        "            \"ticker\": ticker,\n",
        "            \"metric\": metric,\n",
        "            \"window\": len(grp),\n",
        "            \"mean_value\": np.mean(y),\n",
        "            \"pct_change\": pct_change,\n",
        "            \"slope\": slope,\n",
        "            \"volatility\": np.std(np.diff(y)) if len(y) > 1 else np.nan,\n",
        "            \"as_of\": grp[\"as_of\"].max(),\n",
        "        })\n",
        "    trend_df = pd.DataFrame(trend_rows)\n+\n",
        "if trend_df is None or trend_df.empty:\n",
        "    print(\"No trend data available. Populate fundamentals_history or features_fundamental_trends.\")\n",
        "else:\n",
        "    display(trend_df.head(5))\n+\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    sns.histplot(trend_df[\"slope\"].dropna(), bins=50, kde=True)\n",
        "    plt.title(\"Distribution of Fundamental Trend Slopes\")\n",
        "    plt.xlabel(\"Slope\")\n",
        "    plt.ylabel(\"Count\")\n",
        "    plt.show()\n+\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    sns.histplot(trend_df[\"pct_change\"].dropna(), bins=50, kde=True)\n",
        "    plt.title(\"Distribution of Fundamental Percent Change\")\n",
        "    plt.xlabel(\"Percent Change\")\n",
        "    plt.ylabel(\"Count\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Beta distribution (market proxy)\n",
        "\n",
        "Use equal-weight market return as a proxy and compute per-ticker beta across the last 252 days.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if prices is None or prices.empty:\n",
        "    print(\"No prices data available for beta calculation.\")\n",
        "else:\n",
        "    px = prices.copy()\n",
        "    px[\"dt\"] = pd.to_datetime(px[\"dt\"])\n",
        "    px = px.sort_values([\"symbol\", \"dt\"])\n",
        "    px[\"ret1\"] = px.groupby(\"symbol\")[\"close\"].pct_change()\n",
        "\n",
        "    recent = px.groupby(\"symbol\").tail(252)\n",
        "    pivot = recent.pivot(index=\"dt\", columns=\"symbol\", values=\"ret1\").dropna(how=\"all\")\n",
        "\n",
        "    market_ret = pivot.mean(axis=1)\n",
        "    betas = {}\n",
        "    for symbol in pivot.columns:\n",
        "        series = pivot[symbol].dropna()\n",
        "        aligned = series.align(market_ret, join=\"inner\")[0]\n",
        "        if len(aligned) < 60:\n",
        "            continue\n",
        "        mkt = market_ret.loc[aligned.index]\n",
        "        cov = np.cov(aligned, mkt)[0, 1]\n",
        "        var = np.var(mkt)\n",
        "        if var == 0:\n",
        "            continue\n",
        "        betas[symbol] = cov / var\n",
        "\n",
        "    beta_series = pd.Series(betas).dropna()\n",
        "    print(f\"Beta sample size: {len(beta_series)}\")\n",
        "\n",
        "    if not beta_series.empty:\n",
        "        plt.figure(figsize=(10, 4))\n",
        "        sns.histplot(beta_series, bins=50, kde=True)\n",
        "        plt.title(\"Beta Distribution (252d, equal-weight proxy)\")\n",
        "        plt.xlabel(\"Beta\")\n",
        "        plt.ylabel(\"Count\")\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Factor correlation heatmap\n",
        "\n",
        "Compute cross-metric correlations for the latest trend snapshot.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if trend_df is None or trend_df.empty:\n",
        "    print(\"No trend data available for correlation analysis.\")\n",
        "else:\n",
        "    latest_as_of = trend_df[\"as_of\"].max()\n",
        "    latest = trend_df[trend_df[\"as_of\"] == latest_as_of]\n",
        "\n",
        "    wide = latest.pivot_table(index=\"ticker\", columns=\"metric\", values=\"pct_change\")\n",
        "    if wide.shape[1] < 2:\n",
        "        print(\"Not enough metrics to compute correlations.\")\n",
        "    else:\n",
        "        corr = wide.corr()\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        sns.heatmap(corr, cmap=\"coolwarm\", center=0, square=True)\n",
        "        plt.title(\"Factor Correlation (pct_change, latest snapshot)\")\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Summary checks\n",
        "\n",
        "Use this section to validate coverage and track data completeness.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "summary = {\n",
        "    \"fundamentals_history_rows\": int(len(fundamentals_history)) if fundamentals_history is not None else 0,\n",
        "    \"features_trends_rows\": int(len(features_trends)) if features_trends is not None else 0,\n",
        "    \"prices_rows\": int(len(prices)) if prices is not None else 0,\n",
        "}\n",
        "summary\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": ""
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
