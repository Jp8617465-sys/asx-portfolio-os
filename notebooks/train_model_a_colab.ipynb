{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ ASX Portfolio OS - Model A Training (Google Colab)\n",
    "\n",
    "This notebook trains Model A (Technical/Momentum) using your production database.\n",
    "\n",
    "**Steps:**\n",
    "1. Install dependencies\n",
    "2. Build training dataset from database\n",
    "3. Train Model A with hyperparameter tuning\n",
    "4. Download trained model artifacts\n",
    "\n",
    "**Estimated time:** 30-40 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Install dependencies\n",
    "!pip install -q lightgbm==4.1.0 pandas==2.1.4 numpy==1.26.3 scikit-learn==1.3.2 \\\n",
    "    psycopg2-binary==2.9.9 python-dotenv==1.0.0 optuna==3.5.0 \\\n",
    "    matplotlib seaborn joblib shap prefect==2.14.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Set environment variables\n",
    "import os\n",
    "\n",
    "# Database connection\n",
    "os.environ['DATABASE_URL'] = 'postgresql://postgres.gxjqezqndltaelmyctnl:HugoRalph2026_DB_Pass_01@aws-1-ap-southeast-2.pooler.supabase.com:6543/postgres'\n",
    "\n",
    "# Training configuration\n",
    "os.environ['LOOKBACK_MONTHS'] = '36'\n",
    "os.environ['CV_FOLDS'] = '12'\n",
    "os.environ['MODEL_VERSION'] = 'v1_2'\n",
    "os.environ['BATCH_SIZE'] = '100'\n",
    "\n",
    "print('‚úÖ Environment configured')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Download the repository code\n",
    "!git clone https://github.com/Jp8617465-sys/asx-portfolio-os.git\n",
    "%cd asx-portfolio-os\n",
    "!mkdir -p outputs data/training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Build Training Dataset\n",
    "\n",
    "This fetches 36 months of price data from your database and computes features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the training dataset\n",
    "%run jobs/build_training_dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify dataset was created\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('outputs/model_a_training_dataset.csv')\n",
    "print(f\"‚úÖ Dataset loaded: {len(df):,} rows, {df['symbol'].nunique()} symbols\")\n",
    "print(f\"‚úÖ Date range: {df['dt'].min()} to {df['dt'].max()}\")\n",
    "print(f\"\\nFeatures: {[c for c in df.columns if c not in ['dt', 'symbol', 'close', 'volume', 'return_1m_fwd']]}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Train Model A (Standard)\n",
    "\n",
    "Train with default hyperparameters (faster, ~10-15 minutes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model A with default parameters\n",
    "%run models/train_model_a_ml.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî¨ Train Model A with Hyperparameter Tuning (Optional)\n",
    "\n",
    "Use Optuna to optimize hyperparameters (slower, ~30 minutes, better performance).\n",
    "\n",
    "**Skip this if you already trained above.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Hyperparameter tuning with Optuna\n",
    "import sys\n",
    "sys.argv = ['', '--tune-hyperparams', '--n-trials', '30']\n",
    "%run scripts/train_production_models.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì• Download Trained Model\n",
    "\n",
    "Download the trained model artifacts to your local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all generated files\n",
    "!ls -lh outputs/\n",
    "\n",
    "# Zip all outputs for download\n",
    "!zip -r model_a_artifacts.zip outputs/\n",
    "\n",
    "from google.colab import files\n",
    "files.download('model_a_artifacts.zip')\n",
    "\n",
    "print(\"\\n‚úÖ Download the model_a_artifacts.zip file from the Files panel (left sidebar)\")\n",
    "print(\"üìÅ Extract it and upload the .pkl files to your Render deployment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Model Performance Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display training results\n",
    "import json\n",
    "\n",
    "with open('outputs/model_a_v1_2_metrics.json', 'r') as f:\n",
    "    metrics = json.load(f)\n",
    "\n",
    "print(\"üéØ Model A Performance:\")\n",
    "print(f\"   ROC-AUC: {metrics.get('roc_auc_mean', 'N/A'):.4f}\")\n",
    "print(f\"   RMSE: {metrics.get('rmse_mean', 'N/A'):.4f}\")\n",
    "print(f\"   Sharpe Ratio: {metrics.get('sharpe_ratio', 'N/A'):.2f}\")\n",
    "\n",
    "print(\"\\n‚úÖ Training complete!\")\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Download model_a_artifacts.zip\")\n",
    "print(\"2. Upload .pkl files to Render at /app/outputs/\")\n",
    "print(\"3. Restart Render service to load new model\")\n",
    "print(\"4. Validate: curl https://asx-portfolio-os.onrender.com/model/status/summary\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
